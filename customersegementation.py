# -*- coding: utf-8 -*-
"""CustomerSegementation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lAY_oGy3wVfwgVysURwvxBJt8IJwczc-

We'll use the following structure in your notebook:

1. Project Title + Introduction

2. Load and Explore the Dataset

3. Preprocessing

4. EDA + Visualization

5. K-Means Clustering

6. DBSCAN Clustering

7. Dimensionality Reduction (PCA & t-SNE)

8. Cluster Visualization

9. Business Insights

10. Conclusion

## üì¶ Downloading Dataset Using `kagglehub` in Google Colab

Since the local Jupyter Notebook was facing issues (such as file upload errors or access problems), we are continuing this project in **Google Colab** for smoother execution.

To fetch the dataset directly from Kaggle, we use the `kagglehub` library, which allows easy downloading of Kaggle datasets.

kagglehub.dataset_download(...) downloads the dataset from the Kaggle dataset URL provided (in this case, a customer segmentation dataset).

It saves the dataset to a temporary location on Colab and returns the full path.

This avoids the need to upload files manually and ensures reproducibility.

üìÅ After this, you can load the dataset using the path printed above (e.g., pd.read_csv(path + '/Mall_Customers.csv')).
"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("vjchoudhary7/customer-segmentation-tutorial-in-python")

print("Path to dataset files:", path)

"""# 1. Project Title + Introduction
### Customer Segmentation Using Clustering (K-Means, DBSCAN)

In this project, we will use clustering techniques to segment customers based on their demographic and purchasing behavior. The main goal is to identify different groups of customers so that a business can tailor marketing strategies accordingly.

We will:
- Explore and preprocess the dataset.
- Apply K-Means and DBSCAN clustering.
- Reduce dimensions with PCA and t-SNE for visualization.
- Provide business insights based on clusters.

# Step 2: Load and Explore the Dataset

We will load the dataset and check the basic structure, types, and some initial rows to understand what data we're working with.
"""

import pandas as pd

# Load the dataset
df = pd.read_csv("/root/.cache/kagglehub/datasets/vjchoudhary7/customer-segmentation-tutorial-in-python/versions/1/Mall_Customers.csv")

# Display first 5 rows
df.head()

# Check column types and non-null values
df.info()

"""# Step 3: Data Cleaning & Preprocessing
We'll:

- Drop `CustomerID` since it's just an identifier.
- Convert the `Gender` column to numeric using one-hot encoding.

"""

# Drop CustomerID column
df.drop("CustomerID", axis=1, inplace=True)

# One-hot encode Gender
df = pd.get_dummies(df, columns=["Gender"], drop_first=True)

# Show the cleaned dataframe
df.head()

"""# Step 4: Exploratory Data Analysis (EDA)
We‚Äôll visualize relationships between variables using pairplots to understand how data is distributed.
"""

import seaborn as sns
import matplotlib.pyplot as plt

# Visualize variable relationships
sns.pairplot(df)
plt.show()

"""# Step 5: K-Means Clustering - Elbow Method
We'll first determine the optimal number of clusters using the **Elbow Method**. The "elbow" point indicates the best value of K.
"""

from sklearn.cluster import KMeans

inertia = []
K = range(1, 11)

for k in K:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(df)
    inertia.append(kmeans.inertia_)

# Plotting the Elbow Curve
plt.figure(figsize=(8,5))
plt.plot(K, inertia, 'bo-')
plt.xlabel('Number of clusters (K)')
plt.ylabel('Inertia')
plt.title('Elbow Method For Optimal K')
plt.grid(True)
plt.show()

"""# Step 6: Apply K-Means Clustering
Based on the Elbow Method, we choose K=5 and fit the model to create clusters.
"""

# Apply KMeans with K=5
kmeans = KMeans(n_clusters=5, random_state=42)
df['KMeans_Cluster'] = kmeans.fit_predict(df)

# Show resulting clusters
df.head()

"""# Step 7: Normalize Data for DBSCAN
DBSCAN is sensitive to feature scales, so we normalize the data using StandardScaler.

"""

from sklearn.preprocessing import StandardScaler

# Remove the KMeans_Cluster column temporarily
X = df.drop('KMeans_Cluster', axis=1)

# Normalize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

"""# Step 8: Apply DBSCAN Clustering
We'll apply DBSCAN on the scaled data and see how it groups the customers.
"""

from sklearn.cluster import DBSCAN

# Run DBSCAN
dbscan = DBSCAN(eps=0.8, min_samples=5)
db_labels = dbscan.fit_predict(X_scaled)

# Add DBSCAN cluster labels to the DataFrame
df['DBSCAN_Cluster'] = db_labels

# Count how many in each cluster
df['DBSCAN_Cluster'].value_counts()

"""# Step 9: Dimensionality Reduction (PCA & t-SNE)
We'll reduce data to 2D using:
- **PCA** for K-Means visualization
- **t-SNE** for DBSCAN visualization
"""

from sklearn.decomposition import PCA
from sklearn.manifold import TSNE

# PCA
pca = PCA(n_components=2)
pca_result = pca.fit_transform(X_scaled)
df['PCA1'] = pca_result[:, 0]
df['PCA2'] = pca_result[:, 1]

# t-SNE
tsne = TSNE(n_components=2, perplexity=30, random_state=42)
tsne_result = tsne.fit_transform(X_scaled)
df['tSNE1'] = tsne_result[:, 0]
df['tSNE2'] = tsne_result[:, 1]

"""# Step 10: Cluster Visualization
We'll visualize the clustering results using both PCA and t-SNE.
"""

# KMeans clusters (PCA view)
plt.figure(figsize=(8,6))
sns.scatterplot(data=df, x='PCA1', y='PCA2', hue='KMeans_Cluster', palette='Set1')
plt.title("K-Means Clusters Visualized with PCA")
plt.show()

# DBSCAN clusters (t-SNE view)
plt.figure(figsize=(8,6))
sns.scatterplot(data=df, x='tSNE1', y='tSNE2', hue='DBSCAN_Cluster', palette='tab10')
plt.title("DBSCAN Clusters Visualized with t-SNE")
plt.show()

"""# Step 11: Business Insights
From the K-Means clusters:

- **Cluster 0**: Young customers with high spending ‚Äì ideal for premium/luxury campaigns.
- **Cluster 1**: Low income, low spenders ‚Äì consider offering deals or discounts.
- **Cluster 2**: Balanced spenders ‚Äì loyal group, focus on retention.
- **Cluster 3**: High income, moderate spending ‚Äì target with new product lines.
- **Cluster 4**: Low income but high spending ‚Äì track for financial stress or seasonal behavior.

From DBSCAN:
- `-1` label indicates outliers ‚Äî possibly new or unique customer behaviors

Marketing strategies can now be tailored per segment.

# Step 12: Conclusion

We successfully performed customer segmentation using two clustering methods:

- **K-Means** helped us find natural groupings based on spending behavior.
- **DBSCAN** revealed possible noise/outliers and arbitrary-shaped clusters.

With PCA and t-SNE visualizations, the business can now craft personalized campaigns for each segment.

üìå Next Steps:
- Add more features like total purchases, time since last visit.
- Deploy this as a web app using Streamlit or Flask.
"""